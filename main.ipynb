{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92d969d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6450f945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analisis_cancer.csv':    id  cancer_stage  tumor_size early_detection inflammatory_bowel_disease  \\\n",
       " 0   1             3    2.788441              No                         No   \n",
       " 1   2             1    1.049699              No                        Yes   \n",
       " 2   3             3    8.339153              No                         No   \n",
       " 3   4             3    7.361716              No                         No   \n",
       " 4   5             1    7.561065              No                         No   \n",
       " \n",
       "   relapse  \n",
       " 0      No  \n",
       " 1      No  \n",
       " 2      No  \n",
       " 3      No  \n",
       " 4      No  ,\n",
       " 'analisis_sangre_dataset.csv':     id  Hemoglobina  Plaquetas  Globulos blancos  Globulos rojos  Glucosa  HDL\n",
       " 0  109         10.4     180000              5700             3.7       77   25\n",
       " 1  150         13.8     320000              7500             5.4       92   30\n",
       " 2  194         13.5     370000              8500             5.1       90   29\n",
       " 3  171         12.7     290000              7800             4.8       86   29\n",
       " 4  189         14.9     380000              8700             5.7       95   31,\n",
       " 'historial_medico.csv':    id Sexo  Age Family history smoke alcohol     obesity      diet  \\\n",
       " 0   1    M   77             No    No     Yes  Overweight       Low   \n",
       " 1   2    M   59             No    No      No  Overweight  Moderate   \n",
       " 2   3    M   83             No    No      No       Obese      High   \n",
       " 3   4    M   66             No   Yes      No      Normal       Low   \n",
       " 4   5    F   79             No   Yes      No  Overweight       Low   \n",
       " \n",
       "   Screening_History Healthcare_Access Survival_Prediction  \n",
       " 0           Regular          Moderate                 Yes  \n",
       " 1           Regular              High                 Yes  \n",
       " 2           Regular          Moderate                 Yes  \n",
       " 3             Never              High                 Yes  \n",
       " 4             Never              High                 Yes  ,\n",
       " 'historial_medico_imagenes.csv':    id imagename\n",
       " 0   1   colonn1\n",
       " 1   2   colonn2\n",
       " 2   3   colonn3\n",
       " 3   4   colonn4\n",
       " 4   5   colonn5}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar todos los CSV que has subido\n",
    "df_cancer = pd.read_csv(\"data/analisis_cancer.csv\")\n",
    "df_sangre = pd.read_csv(\"data/analisis_sangre_dataset.csv\")\n",
    "df_historial = pd.read_csv(\"data/historial_medico.csv\")\n",
    "df_imagenes = pd.read_csv(\"data/historial_medico_imagenes.csv\")\n",
    "\n",
    "# Mostrar una vista rápida de cada uno para saber qué contiene\n",
    "resumen = {\n",
    "    \"analisis_cancer.csv\": df_cancer.head(),\n",
    "    \"analisis_sangre_dataset.csv\": df_sangre.head(),\n",
    "    \"historial_medico.csv\": df_historial.head(),\n",
    "    \"historial_medico_imagenes.csv\": df_imagenes.head()\n",
    "}\n",
    "\n",
    "resumen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3a40601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id Sexo  Age Family history smoke alcohol     obesity      diet  \\\n",
      "0   1    M   77             No    No     Yes  Overweight       Low   \n",
      "1   2    M   59             No    No      No  Overweight  Moderate   \n",
      "2   3    M   83             No    No      No       Obese      High   \n",
      "3   4    M   66             No   Yes      No      Normal       Low   \n",
      "4   5    F   79             No   Yes      No  Overweight       Low   \n",
      "\n",
      "  Screening_History Healthcare_Access  ... early_detection  \\\n",
      "0           Regular          Moderate  ...              No   \n",
      "1           Regular              High  ...              No   \n",
      "2           Regular          Moderate  ...              No   \n",
      "3             Never              High  ...              No   \n",
      "4             Never              High  ...              No   \n",
      "\n",
      "   inflammatory_bowel_disease  relapse Hemoglobina Plaquetas Globulos blancos  \\\n",
      "0                          No       No        12.3    290000             7400   \n",
      "1                         Yes       No        13.4    390000             8900   \n",
      "2                          No       No        14.0    360000             8200   \n",
      "3                          No       No        13.2    340000             7800   \n",
      "4                          No       No        13.5    350000             8000   \n",
      "\n",
      "   Globulos rojos  Glucosa  HDL  imagename  \n",
      "0             4.6       88   29    colonn1  \n",
      "1             5.7       94   31    colonn2  \n",
      "2             5.6       93   31    colonn3  \n",
      "3             5.3       91   30    colonn4  \n",
      "4             5.1       90   29    colonn5  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "Index(['id', 'Sexo', 'Age', 'Family history', 'smoke', 'alcohol', 'obesity',\n",
      "       'diet', 'Screening_History', 'Healthcare_Access', 'Survival_Prediction',\n",
      "       'cancer_stage', 'tumor_size', 'early_detection',\n",
      "       'inflammatory_bowel_disease', 'relapse', 'Hemoglobina', 'Plaquetas',\n",
      "       'Globulos blancos', 'Globulos rojos', 'Glucosa', 'HDL', 'imagename'],\n",
      "      dtype='object')\n",
      "(200, 23)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Renombrar por si acaso 'Id' estuviera aún en alguno\n",
    "df_historial = df_historial.rename(columns={\"Id\": \"id\"})\n",
    "df_imagenes = df_imagenes.rename(columns={\"Id\": \"id\"})\n",
    "\n",
    "# Unir los datasets usando 'id'\n",
    "df_completo = df_historial.merge(df_cancer, on=\"id\", how=\"left\")\n",
    "df_completo = df_completo.merge(df_sangre, on=\"id\", how=\"left\")\n",
    "df_completo = df_completo.merge(df_imagenes, on=\"id\", how=\"left\")\n",
    "\n",
    "# Mostrar tabla combinada\n",
    "print(df_completo.head())  # Ver las primeras filas\n",
    "print(df_completo.columns)  # Ver las columnas disponibles\n",
    "print(df_completo.shape)  # Ver dimensiones (filas, columnas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d326ea71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.675\n",
      "Matriz de confusión:\n",
      " [[11  8]\n",
      " [ 5 16]]\n",
      "Informe de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.58      0.63        19\n",
      "           1       0.67      0.76      0.71        21\n",
      "\n",
      "    accuracy                           0.68        40\n",
      "   macro avg       0.68      0.67      0.67        40\n",
      "weighted avg       0.68      0.68      0.67        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# 1. Cargar datos (en tu caso ya tienes df_completo)\n",
    "df = df_completo.copy()\n",
    "\n",
    "# 2. Convertir variable objetivo a 0 y 1\n",
    "df['Survival_Prediction'] = df['Survival_Prediction'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# 3. Eliminar columnas no útiles (id, imagename)\n",
    "df = df.drop(columns=['id', 'imagename'])\n",
    "\n",
    "# 4. Codificar variables categóricas\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "# 5. Separar features y target\n",
    "X = df.drop(columns=['Survival_Prediction'])\n",
    "y = df['Survival_Prediction']\n",
    "\n",
    "# 6. Dividir en train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 7. Entrenar modelo\n",
    "model = RandomForestClassifier(n_estimators=200, max_depth=6, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 8. Predecir\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 9. Evaluar\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Matriz de confusión:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Informe de clasificación:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "87a92a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.625,\n",
       " array([[ 8, 11],\n",
       "        [ 4, 17]]),\n",
       " '              precision    recall  f1-score   support\\n\\n           0       0.67      0.42      0.52        19\\n           1       0.61      0.81      0.69        21\\n\\n    accuracy                           0.62        40\\n   macro avg       0.64      0.62      0.61        40\\nweighted avg       0.64      0.62      0.61        40\\n',\n",
       " {'max_depth': 4,\n",
       "  'min_samples_leaf': 2,\n",
       "  'min_samples_split': 2,\n",
       "  'n_estimators': 200})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Copia del dataset\n",
    "df = df_completo.copy()\n",
    "\n",
    "# Convertir variable objetivo\n",
    "df[\"Survival_Prediction\"] = df[\"Survival_Prediction\"].map({\"Yes\": 1, \"No\": 0})\n",
    "\n",
    "# Eliminar columnas que no aportan directamente al modelo\n",
    "df = df.drop(columns=[\"id\", \"imagename\"])\n",
    "\n",
    "# Codificar variables categóricas\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "# Separar features y target\n",
    "X = df.drop(columns=[\"Survival_Prediction\"])\n",
    "y = df[\"Survival_Prediction\"]\n",
    "\n",
    "# Separar en train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definir la rejilla de hiperparámetros\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [4, 6, 8],\n",
    "    \"min_samples_split\": [2, 4, 6],\n",
    "    \"min_samples_leaf\": [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Inicializar GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Ejecutar búsqueda\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Predecir con el mejor modelo\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluar\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "mejores_parametros = grid_search.best_params_\n",
    "\n",
    "accuracy, conf_matrix, report, mejores_parametros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c71b2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: {'max_depth': 4, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Accuracy: 1.0\n",
      "Matriz de confusión:\n",
      " [[19  0]\n",
      " [ 0 21]]\n",
      "Informe de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           1.00        40\n",
      "   macro avg       1.00      1.00      1.00        40\n",
      "weighted avg       1.00      1.00      1.00        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Copia del dataframe original\n",
    "df = df_completo.copy()\n",
    "\n",
    "# Convertir variable objetivo\n",
    "df[\"Survival_Prediction\"] = df[\"Survival_Prediction\"].map({\"Yes\": 1, \"No\": 0})\n",
    "\n",
    "# Eliminar columna 'id' si existe\n",
    "if \"id\" in df.columns:\n",
    "    df = df.drop(columns=[\"id\"])\n",
    "\n",
    "# Codificar variables categóricas\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "# Separar variables\n",
    "X = df.drop(columns=[\"Survival_Prediction\"])\n",
    "y = df[\"Survival_Prediction\"]\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Grid de hiperparámetros\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [4, 6, 8],\n",
    "    \"min_samples_split\": [2, 4, 6],\n",
    "    \"min_samples_leaf\": [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Búsqueda de hiperparámetros con validación cruzada\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Predicción y evaluación\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"Mejores hiperparámetros:\", grid_search.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Matriz de confusión:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Informe de clasificación:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3452ada4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top variables más importantes en el modelo:\n",
      "\n",
      "                  Variable  Importancia\n",
      "                 imagename     0.506500\n",
      "                tumor_size     0.215068\n",
      "                 Plaquetas     0.040198\n",
      "               Hemoglobina     0.031345\n",
      "            Globulos rojos     0.029458\n",
      "          Globulos blancos     0.029333\n",
      "                       Age     0.022502\n",
      "                   Glucosa     0.021674\n",
      "         Healthcare_Access     0.019984\n",
      "                      diet     0.016785\n",
      "                       HDL     0.010900\n",
      "            Family history     0.010418\n",
      "              cancer_stage     0.009090\n",
      "                   obesity     0.006502\n",
      "inflammatory_bowel_disease     0.006271\n"
     ]
    }
   ],
   "source": [
    "# Obtener la importancia de cada variable del mejor modelo\n",
    "importances = best_model.feature_importances_\n",
    "features = X.columns\n",
    "\n",
    "# Combinar en un DataFrame y ordenarlo\n",
    "feat_importance = pd.DataFrame({\n",
    "    \"Variable\": features,\n",
    "    \"Importancia\": importances\n",
    "}).sort_values(by=\"Importancia\", ascending=False)\n",
    "\n",
    "# Mostrar top 15\n",
    "print(\"Top variables más importantes en el modelo:\\n\")\n",
    "print(feat_importance.head(15).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ffcd9309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: {'max_depth': 4, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Accuracy: 0.625\n",
      "Matriz de confusión:\n",
      " [[ 8 11]\n",
      " [ 4 17]]\n",
      "Informe de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.42      0.52        19\n",
      "           1       0.61      0.81      0.69        21\n",
      "\n",
      "    accuracy                           0.62        40\n",
      "   macro avg       0.64      0.62      0.61        40\n",
      "weighted avg       0.64      0.62      0.61        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Copia del dataset original\n",
    "df = df_completo.copy()\n",
    "\n",
    "# Eliminar columnas que no deben usarse\n",
    "df = df.drop(columns=[\"imagename\", \"id\"], errors=\"ignore\")\n",
    "\n",
    "# Convertir variable objetivo\n",
    "df[\"Survival_Prediction\"] = df[\"Survival_Prediction\"].map({\"Yes\": 1, \"No\": 0})\n",
    "\n",
    "# Codificar variables categóricas\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "# Separar datos\n",
    "X = df.drop(columns=[\"Survival_Prediction\"])\n",
    "y = df[\"Survival_Prediction\"]\n",
    "\n",
    "# División train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hiperparámetros a probar\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [4, 6, 8],\n",
    "    \"min_samples_split\": [2, 4],\n",
    "    \"min_samples_leaf\": [1, 2]\n",
    "}\n",
    "\n",
    "# Grid search con validación cruzada\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Evaluación\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"Mejores hiperparámetros:\", grid_search.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Matriz de confusión:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Informe de clasificación:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e40f2f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.65,\n",
       " array([[ 8, 11],\n",
       "        [ 3, 18]]),\n",
       " '              precision    recall  f1-score   support\\n\\n           0       0.73      0.42      0.53        19\\n           1       0.62      0.86      0.72        21\\n\\n    accuracy                           0.65        40\\n   macro avg       0.67      0.64      0.63        40\\nweighted avg       0.67      0.65      0.63        40\\n')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamiento con class_weight='balanced' para penalizar más los errores en la clase minoritaria (clase 0)\n",
    "model_weighted = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=4,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=2,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Entrenar\n",
    "model_weighted.fit(X_train, y_train)\n",
    "\n",
    "# Evaluación\n",
    "y_pred_weighted = model_weighted.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred_weighted)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_weighted)\n",
    "report = classification_report(y_test, y_pred_weighted)\n",
    "\n",
    "accuracy, conf_matrix, report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "372695f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Modelo guardado como modelo_supervivencia_rf.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "joblib.dump(model_weighted, \"modelo_supervivencia_rf.pkl\")\n",
    "\n",
    "print(\"✅ Modelo guardado como modelo_supervivencia_rf.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d67ad0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Matriz de correlación guardada como matriz_correlacion.csv\n"
     ]
    }
   ],
   "source": [
    "# Prepara datos\n",
    "df_corr = df_completo.drop(columns=[\"id\", \"imagename\"], errors=\"ignore\").copy()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "for col in df_corr.columns:\n",
    "    if df_corr[col].dtype == \"object\":\n",
    "        df_corr[col] = LabelEncoder().fit_transform(df_corr[col])\n",
    "\n",
    "# Calcular correlación y guardar como CSV\n",
    "correlation_matrix = df_corr.corr()\n",
    "correlation_matrix.to_csv(\"matriz_correlacion.csv\")\n",
    "\n",
    "print(\"✅ Matriz de correlación guardada como matriz_correlacion.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3fcc32e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas eliminadas por alta correlación (> 0.85):\n",
      "['Globulos blancos', 'Globulos rojos', 'Glucosa', 'HDL', 'Plaquetas']\n",
      "✅ Dataset guardado como df_sin_correlaciones_altas.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar la matriz de correlación exportada (ya codificada)\n",
    "cor_matrix = pd.read_csv(\"matriz_correlacion.csv\", index_col=0)\n",
    "\n",
    "# Umbral de correlación (puedes ajustarlo)\n",
    "umbral = 0.85\n",
    "\n",
    "# Encontrar columnas altamente correlacionadas\n",
    "columnas_correladas = set()\n",
    "for i in range(len(cor_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(cor_matrix.iloc[i, j]) > umbral:\n",
    "            colname = cor_matrix.columns[i]\n",
    "            columnas_correladas.add(colname)\n",
    "\n",
    "# Mostrar columnas que se van a eliminar\n",
    "print(\"Columnas eliminadas por alta correlación (> 0.85):\")\n",
    "print(sorted(columnas_correladas))\n",
    "\n",
    "# Aplicar la eliminación al DataFrame original codificado\n",
    "# (Asegúrate de usar un DataFrame con las mismas columnas que esta matriz)\n",
    "df_codificado = df_completo.drop(columns=[\"id\", \"imagename\"], errors=\"ignore\").copy()\n",
    "\n",
    "# Codificar categorías como antes\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "for col in df_codificado.columns:\n",
    "    if df_codificado[col].dtype == \"object\":\n",
    "        df_codificado[col] = LabelEncoder().fit_transform(df_codificado[col])\n",
    "\n",
    "# Eliminar las columnas altamente correlacionadas\n",
    "df_filtrado = df_codificado.drop(columns=columnas_correladas)\n",
    "\n",
    "# Guardar resultado\n",
    "df_filtrado.to_csv(\"df_sin_correlaciones_altas.csv\", index=False)\n",
    "print(\"✅ Dataset guardado como df_sin_correlaciones_altas.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "57a2e772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.825\n",
      "Matriz de confusión:\n",
      " [[15  4]\n",
      " [ 3 18]]\n",
      "Informe de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81        19\n",
      "           1       0.82      0.86      0.84        21\n",
      "\n",
      "    accuracy                           0.82        40\n",
      "   macro avg       0.83      0.82      0.82        40\n",
      "weighted avg       0.83      0.82      0.82        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Cargar el dataset limpio\n",
    "df = pd.read_csv(\"df_sin_correlaciones_altas.csv\")\n",
    "\n",
    "# Variable objetivo\n",
    "y = df[\"Survival_Prediction\"]\n",
    "X = df.drop(columns=[\"Survival_Prediction\"])\n",
    "\n",
    "# División train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modelo con pesos balanceados\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=4,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=2,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Entrenar\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluación\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Matriz de confusión:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Informe de clasificación:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ff226ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Modelo guardado como modelo_final_rf.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Guardar modelo entrenado\n",
    "joblib.dump(model, \"modelo_final_rf.pkl\")\n",
    "\n",
    "print(\"✅ Modelo guardado como modelo_final_rf.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f452698c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 0 0 1 0 1 1 1 0 0 0 0 0 1 0 1 1 0 1 0 1 1 0 1 0 0 1 1 1 1 1 0 0 1\n",
      " 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Cargar el modelo\n",
    "modelo_cargado = joblib.load(\"modelo_final_rf.pkl\")\n",
    "\n",
    "# Usarlo para predecir\n",
    "y_pred = modelo_cargado.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b9169631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sexo', 'Age', 'Family history', 'smoke', 'alcohol', 'obesity', 'diet', 'Screening_History', 'Healthcare_Access', 'cancer_stage', 'tumor_size', 'early_detection', 'inflammatory_bowel_disease', 'relapse', 'Hemoglobina']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"df_sin_correlaciones_altas.csv\")\n",
    "print(df.drop(columns=[\"Survival_Prediction\"]).columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb51777",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/data/modelo_rf_ohe.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[61]\u001b[39m\u001b[32m, line 63\u001b[39m\n\u001b[32m     60\u001b[39m report = classification_report(y_test, y_pred)\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# Guardar el pipeline completo\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/mnt/data/modelo_rf_ohe.pkl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m accuracy, conf_matrix, report\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Escritorio/cancer_prediction/venv/lib/python3.12/site-packages/joblib/numpy_pickle.py:552\u001b[39m, in \u001b[36mdump\u001b[39m\u001b[34m(value, filename, compress, protocol, cache_size)\u001b[39m\n\u001b[32m    550\u001b[39m         NumpyPickler(f, protocol=protocol).dump(value)\n\u001b[32m    551\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_filename:\n\u001b[32m--> \u001b[39m\u001b[32m552\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mwb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    553\u001b[39m         NumpyPickler(f, protocol=protocol).dump(value)\n\u001b[32m    554\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/mnt/data/modelo_rf_ohe.pkl'"
     ]
    }
   ],
   "source": [
    "# Repetir el proceso tras el reinicio del entorno\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import joblib\n",
    "\n",
    "# Cargar el dataset limpio sin variables altamente correlacionadas\n",
    "df = pd.read_csv(\"df_sin_correlaciones_altas.csv\")\n",
    "\n",
    "# Separar variables y target\n",
    "y = df[\"Survival_Prediction\"]\n",
    "X = df.drop(columns=[\"Survival_Prediction\"])\n",
    "\n",
    "# Detectar columnas categóricas para aplicar One-Hot Encoding\n",
    "columnas_categoricas = [\n",
    "    \"Sexo\", \"Family history\", \"smoke\", \"alcohol\", \"obesity\", \"diet\",\n",
    "    \"Screening_History\", \"Healthcare_Access\", \"early_detection\",\n",
    "    \"inflammatory_bowel_disease\", \"relapse\"\n",
    "]\n",
    "\n",
    "# Las restantes se dejan como numéricas\n",
    "columnas_numericas = [col for col in X.columns if col not in columnas_categoricas]\n",
    "\n",
    "# Definir el preprocesador\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), columnas_categoricas),\n",
    "        (\"num\", StandardScaler(), columnas_numericas)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Crear el pipeline con RandomForest\n",
    "pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=4,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=2,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Dividir en entrenamiento y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar\n",
    "y_pred = pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Guardar el pipeline completo\n",
    "joblib.dump(pipeline, \"modelo_rf_ohe.pkl\")\n",
    "\n",
    "accuracy, conf_matrix, report\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
